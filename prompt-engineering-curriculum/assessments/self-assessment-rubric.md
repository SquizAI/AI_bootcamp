# Self-Assessment Rubric: Evaluating Your Own Prompts

## What This Tool Is For

This rubric helps you evaluate your own prompts and understand how to make them better. It's designed to help you learn, not to judge you. Use it to reflect on your work and identify areas where you're getting stronger.

---

## How to Use This Rubric

1. **After you write a prompt**, go through each criterion below
2. **Choose the level that best describes your prompt** (Beginner, Developing, Proficient, Advanced)
3. **Write notes** about what worked and what you'd improve next time
4. **Use the reflection questions** to think deeply about your process
5. **Track your progress** across multiple prompts to see yourself getting better

---

## Criteria for Evaluating Prompts

### Criterion 1: Role (Who should the AI be?)

**Advanced: You clearly assign a specific, detailed role**
- You specify exactly who the AI should be (teacher, tutor, editor, coach, etc.)
- You might include expertise level or teaching style
- Example: "Act as a patient biology tutor who uses real-world examples"
- Result: AI adopts the right persona and responds appropriately

**Proficient: You assign a clear role**
- You tell the AI who to be (teacher, tutor, coach)
- You might include the subject
- Example: "Act as a math tutor"
- Result: AI responds in an appropriate expert voice

**Developing: You hint at a role but it's not explicit**
- You might say "help me understand" (implies teacher role)
- Role is vague or generic
- Example: "Explain how photosynthesis works"
- Result: AI responds, but might not match your needs

**Beginner: You don't assign a role**
- Your prompt doesn't mention who the AI should be
- You just ask a question directly
- Example: "What is photosynthesis?"
- Result: Generic response, might be at wrong level or tone

---

### Criterion 2: Context (What does the AI need to know about you?)

**Advanced: You provide rich, specific context**
- You share your grade level AND specific prior knowledge
- You explain what specifically you're struggling with
- You mention learning style preferences or assignment requirements
- Example: "I'm a 9th grader. I understand that plants need sunlight and water, but I don't get what's actually happening in the cells. I learn best with analogies rather than technical descriptions."
- Result: AI tailors response perfectly to your situation

**Proficient: You provide relevant context**
- You mention your grade level or what you know
- You explain what you need help with
- Example: "I'm a 7th grader and I don't understand photosynthesis"
- Result: AI responds at appropriate level and addresses your gap

**Developing: You provide some context but it's incomplete**
- You mention one or two pieces of context
- Context is vague
- Example: "I'm learning about photosynthesis but confused"
- Result: AI makes some assumptions that might not match your needs

**Beginner: You provide little or no context**
- Nothing about grade level, prior knowledge, or specific struggle
- Just the topic
- Example: "Tell me about photosynthesis"
- Result: AI gives generic response; might be too simple or too complex

---

### Criterion 3: Task (What exactly do you want the AI to do?)

**Advanced: You clearly specify the exact outcome**
- You're specific about what kind of help you need (explain concept, check work, generate practice problems, give feedback, etc.)
- You state the purpose clearly
- Example: "Help me understand WHY the process works, not just HOW to do it"
- Result: AI focuses on exactly what you need

**Proficient: You state your main request clearly**
- Your request is understandable and specific
- Example: "Explain photosynthesis to me"
- Result: AI knows what you're asking for

**Developing: Your request is somewhat unclear**
- Your task is implied but not stated directly
- Multiple interpretations possible
- Example: "Tell me about photosynthesis"
- Result: AI might misunderstand what kind of help you need

**Beginner: Your request is vague**
- Unclear what you actually want
- Could mean many different things
- Example: "Photosynthesis?"
- Result: AI guesses, probably gets it wrong

---

### Criterion 4: Format (How should the AI structure the response?)

**Advanced: You specify detailed format preferences**
- You explain exactly how you want the response organized
- You might request specific structures (step-by-step, bullet points, questions to test understanding, analogy, etc.)
- Example: "Explain this with an analogy I'd recognize from daily life, then show the actual science"
- Result: Response is exactly the format you can best learn from

**Proficient: You mention desired format**
- You request a specific structure
- Example: "Explain it step-by-step" or "Use bullet points"
- Result: Response is organized in a helpful way

**Developing: Format is implied but not explicit**
- You might say "explain simply" without specifying structure
- Format preference is vague
- Example: "Keep it short"
- Result: AI tries but might not match your preference

**Beginner: You don't specify format**
- Nothing about how you want the response structured
- Example: Just the question
- Result: AI chooses format; might not be most helpful for you

---

### Criterion 5: Constraints (What should the AI NOT do?)

**Advanced: You include clear, strategic constraints**
- You use multiple relevant constraints to prevent unhelpful responses
- Constraints protect your learning (don't solve for me) and your specific needs
- Example: "Don't give me the answer directly—guide my thinking with questions. Explain at 9th grade level. Focus only on aerobic respiration."
- Result: AI stays within boundaries that support your learning

**Proficient: You include relevant constraints**
- You specify something the AI should avoid
- Example: "Don't solve this for me—help me understand how to solve it"
- Result: AI respects your learning goal

**Developing: You mention a constraint but it's unclear**
- Constraint is implied or vague
- Example: "Keep it simple"
- Result: AI tries but might not interpret constraint the way you meant

**Beginner: You don't include constraints**
- Nothing about what the AI shouldn't do
- Example: No negative prompting
- Result: AI might do things you don't want (give answers, be too complex, wrong format, etc.)

---

## Overall Prompt Quality: Quick Check

After scoring each criterion, ask yourself:

**Does my prompt have...**
- [ ] A clear role for the AI?
- [ ] Context about who I am and what I know?
- [ ] A specific task/request?
- [ ] Preferred format for the response?
- [ ] Any important constraints?

**If you checked most boxes:** Your prompt is solid! It should get good results.

**If you missed some:** That's the learning opportunity. Which criterion would help most if you improved it?

---

## Reflection Questions

After you write and test a prompt, answer these questions:

### About the Process
1. **What was easy about writing this prompt?** (Role assignment? Context? Constraints?)
2. **What was challenging?**
3. **Which part took the most thought?**

### About the Response
4. **Did the AI understand what you needed?** How do you know?
5. **What parts of the response were most helpful?**
6. **What could have been better about the response?**

### About Improvement
7. **If you could revise the prompt, what would you change?**
8. **Which criterion would most improve the response if you enhanced it?**
9. **What will you do differently next time?**

### About Transfer
10. **How could you use a similar prompt with a different subject?**
11. **What did you learn about prompt engineering from this experience?**

---

## Progress Tracking

Keep a record of your prompts and scores. Over time, you should see:

**Early prompts:**
- Weaker in Context (not providing enough background)
- Weaker in Constraints (not thinking about what to prevent)
- Good at Role and Task (more intuitive)

**Later prompts:**
- All criteria improving
- More intentional choices
- Faster to write quality prompts
- Better at anticipating what AI needs

### Track Your Growth

Use this simple chart to see your progress:

| Prompt # | Topic | Role | Context | Task | Format | Constraints | Notes |
|----------|-------|------|---------|------|--------|-------------|-------|
| 1 | Math | P | D | P | D | B | Role clear but no constraints |
| 2 | Science | P | P | P | P | D | Getting better! |
| 3 | Writing | A | P | A | P | P | Much improved |

**Key:** A = Advanced, P = Proficient, D = Developing, B = Beginner

---

## Common Growth Patterns

**Pattern 1: "I'm getting better at Context"**
- Shows you're thinking about what information the AI needs
- You're personalizing your prompts to your situation
- Next step: Combine with stronger Constraints

**Pattern 2: "My Format is improving"**
- Shows you're thinking about how you learn best
- You understand that structure matters
- Next step: Try different formats for different tasks

**Pattern 3: "Constraints are still weak"**
- This is VERY normal—they're the hardest part
- You're learning to think about prevention
- Next step: Look at your current assignment and write one constraint for it

**Pattern 4: "Everything is improving"**
- You're internalizing prompt engineering
- You're thinking like an AI communicator
- Next step: Try combining techniques (multi-step, few-shot)

---

## Remember

**This rubric is for YOUR learning, not for judgment.**

- Scoring "Developing" is good—it shows you know what to improve
- You'll get better with practice
- Even experienced prompt engineers revise and refine
- The goal is progress, not perfection
- Each prompt teaches you something

---

## Using This Across Your Classes

**In Math:** Strong constraints are crucial ("Don't solve it—help me understand")

**In Science:** Rich context matters ("I understand X, but not Y")

**In Writing:** Format and role are key ("Give feedback like an editor would")

**In History:** Multi-step is powerful ("First causes, then effects, then connections")

**In Any Subject:** All criteria matter, but emphasis changes

---

## One More Thing

**Your best prompts will probably be for:**
- Topics you care about
- Assignments that feel challenging
- Subjects where you have the most context

**This is intentional.** You're most thoughtful when you really need help. That means your strong prompts are usually exactly where they need to be.

Keep practicing. You're learning a skill that will help you in every subject and throughout your education.

**You've got this.**
